{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TreResNet on CIFAR\n",
    "* Use ResNet50, Densenet 121\n",
    "* best 4 out of 8 networks \n",
    "* Compare accuracy for 1 to 4 streams\n",
    "* Use standard autgmentation, no test time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/rene/code/idc/src\n",
      "2\n",
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import scipy.io\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, densenet121\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "PATH = Path('/media/rene/data')\n",
    "\n",
    "# Add the src directory for functions\n",
    "src_dir = Path.cwd().parent.parent / 'src'\n",
    "print(src_dir)\n",
    "sys.path.append(str(src_dir))\n",
    "\n",
    "# import my functions:\n",
    "from utils import make_cfiar10\n",
    "from functions import*\n",
    "from models import*\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-07-12 14:23:50--  https://pjreddie.com/media/files/cifar.tgz\n",
      "Resolving pjreddie.com (pjreddie.com)... 128.208.3.39\n",
      "Connecting to pjreddie.com (pjreddie.com)|128.208.3.39|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 168584360 (161M) [application/octet-stream]\n",
      "Saving to: ‘/media/rene/data/cifar.tgz’\n",
      "\n",
      "cifar.tgz           100%[===================>] 160.77M  47.4MB/s    in 3.4s    \n",
      "\n",
      "2018-07-12 14:23:54 (47.4 MB/s) - ‘/media/rene/data/cifar.tgz’ saved [168584360/168584360]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ! wget https://pjreddie.com/media/files/cifar.tgz -P /media/rene/data\n",
    "# ! tar xzf /media/rene/data/cifar.tgz -C /media/rene/data\n",
    "# ! mv /media/rene/data/cifar /media/rene/data/cifar_raw\n",
    "\n",
    "# ! mkdir /media/rene/data/cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_IN = Path(PATH / 'cifar_raw')\n",
    "# PATH_OUT = PATH / 'cifar'\n",
    "# make_cfiar10(PATH_IN, PATH_OUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train 8 Individial ResNet 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find 4 best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "/media/rene/data/cifar-10-batches-py/models/ResNet50_0\n",
      "Testing model :  0\n",
      "Loss: 0.0043 Acc: 0.9405\n",
      "/media/rene/data/cifar-10-batches-py/models/ResNet50_1\n",
      "Testing model :  1\n",
      "Loss: 0.0044 Acc: 0.9376\n",
      "/media/rene/data/cifar-10-batches-py/models/ResNet50_2\n",
      "Testing model :  2\n",
      "Loss: 0.0043 Acc: 0.9380\n",
      "/media/rene/data/cifar-10-batches-py/models/ResNet50_3\n",
      "Testing model :  3\n",
      "Loss: 0.0047 Acc: 0.9360\n",
      "/media/rene/data/cifar-10-batches-py/models/ResNet50_4\n",
      "Testing model :  4\n",
      "Loss: 0.0042 Acc: 0.9375\n",
      "/media/rene/data/cifar-10-batches-py/models/ResNet50_5\n",
      "Testing model :  5\n",
      "Loss: 0.0042 Acc: 0.9412\n",
      "/media/rene/data/cifar-10-batches-py/models/ResNet50_6\n",
      "Testing model :  6\n",
      "Loss: 0.0042 Acc: 0.9392\n",
      "/media/rene/data/cifar-10-batches-py/models/ResNet50_7\n",
      "Testing model :  7\n",
      "Loss: 0.0041 Acc: 0.9399\n"
     ]
    }
   ],
   "source": [
    "save_path = '/media/rene/data/cifar-10-batches-py/models'\n",
    "PATH = '/media/rene/data'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                   valid_name='valid')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "results = {}\n",
    "\n",
    "for i in range(8):\n",
    "    model_name = 'ResNet50_'+str(i)\n",
    "    model = ResNet50()\n",
    "    device=\"cuda:1\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_path = os.path.join(save_path, model_name)\n",
    "    print(model_path)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print('Testing model : ', i)\n",
    "    valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "    results[model_name] = [valid_acc]\n",
    "    \n",
    "f = open(os.path.join(save_path, \"resnet50_all8.pkl\"),\"wb\")\n",
    "pickle.dump(results,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ResNet50_5', 0.9412), ('ResNet50_0', 0.9405), ('ResNet50_7', 0.9399), ('ResNet50_6', 0.9392), ('ResNet50_2', 0.938), ('ResNet50_1', 0.9376), ('ResNet50_4', 0.9375), ('ResNet50_3', 0.936)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "# save_path = '/home/rene/data/cifar-10-batches-py/models'\n",
    "\n",
    "# with open(os.path.join(save_path, \"resnet50_all8.pkl\"), 'rb') as f:\n",
    "#     results = pickle.load(f)\n",
    "\n",
    "results2 = {key:value[0] for (key,value) in results.items()}\n",
    "sorted_x = sorted(results2.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(sorted_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loss: 0.0080 Acc: 0.9496\n",
      "Fusion2_2s1:  0.00802382983416319 0.9496\n",
      "Loss: 0.0062 Acc: 0.9541\n",
      "Fusion2_2s2:  0.006155912631005049 0.9541\n"
     ]
    }
   ],
   "source": [
    "model_name_list = ['ResNet50_5', 'ResNet50_0', 'ResNet50_7', 'ResNet50_6']\n",
    "num_workers = 6\n",
    "device=\"cuda:0\"\n",
    "batch_size = 32\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "PATH = Path('/media/rene/data/')\n",
    "save_path =  Path(PATH / 'cifar-10-batches-py' / 'models')\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                    valid_name='valid')\n",
    "\n",
    "pretrained_model_list = []\n",
    "for i, model_name in enumerate(model_name_list):\n",
    "    model = ResNet50()\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(save_path, model_name)))\n",
    "    pretrained_model_list.append(model)\n",
    "\n",
    "model = Fusion2(pretrained_model_list, num_input=40, num_output=10)\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_2s1_r2')))\n",
    "model = model.to(device)\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Fusion2_2s1: ', valid_loss, valid_acc)\n",
    "\n",
    "model = Fusion2(pretrained_model_list, num_input=40, num_output=10)\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_2s2_r2')))\n",
    "model = model.to(device)\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Fusion2_2s2: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Fusion with more Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loss: 0.0079 Acc: 0.9464\n",
      "Fusion2_2s1:  0.00793638818487525 0.9464\n",
      "Loss: 0.0065 Acc: 0.9543\n",
      "Fusion2_2s2:  0.006539191658049822 0.9543\n"
     ]
    }
   ],
   "source": [
    "model_name_list = ['ResNet50_5', 'ResNet50_0', 'ResNet50_7', 'ResNet50_6']\n",
    "num_workers = 6\n",
    "device=\"cuda:0\"\n",
    "batch_size = 32\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "PATH = Path('/media/rene/data/')\n",
    "save_path =  Path(PATH / 'cifar-10-batches-py' / 'models')\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                    valid_name='valid')\n",
    "\n",
    "pretrained_model_list = []\n",
    "for i, model_name in enumerate(model_name_list):\n",
    "    model = ResNet50()\n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(os.path.join(save_path, model_name)))\n",
    "    \n",
    "    # remove last layers\n",
    "    res50_conv = ResNet50Bottom(model)\n",
    "    pretrained_model_list.append(res50_conv)\n",
    "\n",
    "model = Fusion2More(pretrained_model_list, num_input=40, num_output=10)\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_2s1_more')))\n",
    "model = model.to(device)\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Fusion2_2s1: ', valid_loss, valid_acc)\n",
    "\n",
    "model = Fusion2More(pretrained_model_list, num_input=40, num_output=10)\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_2s2_more')))\n",
    "model = model.to(device)\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Fusion2_2s2: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Net 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = Path('/home/rene/data/cifar/sample')\n",
    "num_workers = 6\n",
    "batch_size=32\n",
    "epochs = 15\n",
    "\n",
    "models = {}\n",
    "for i in range(8):\n",
    "    models['densenet121_'+str(i)] = densenet121\n",
    "    \n",
    "dataloaders, dataset_sizes = make_batch_gen(str(PATH), batch_size, num_workers, valid_name='valid', size=224)\n",
    "\n",
    "for model_name, model_arch in models.items():\n",
    "    model = model_arch(pretrained=False)\n",
    "    model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "    model = model.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    best_acc, model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
    "                                     epochs, dataloaders, dataset_sizes)\n",
    "    torch.save(model.state_dict(), str(PATH /'models' / model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
