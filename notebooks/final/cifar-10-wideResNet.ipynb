{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide ResNet\n",
    "From: https://github.com/meliketoy/wide-resnet.pytorch/blob/master/networks/wide_resnet.py\n",
    "\n",
    "Just altered the training script to take different save dir\n",
    "The requirements.txt is incorrect, will just havr to guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/rene/code/idc/src\n",
      "2\n",
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "# import pandas as pd\n",
    "from pathlib import Path\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import imshow\n",
    "# from IPython.display import display, HTML\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, densenet121\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "PATH = Path('/media/rene/data')\n",
    "\n",
    "# Add the src directory for functions\n",
    "src_dir = Path.cwd().parent.parent / 'src'\n",
    "print(src_dir)\n",
    "sys.path.append(str(src_dir))\n",
    "sys.path.append('/media/rene/code/wide-resnet.pytorch')\n",
    "\n",
    "\n",
    "# import my functions:\n",
    "from utils import make_cfiar10\n",
    "from functions import*\n",
    "from models import*\n",
    "from networks import Wide_ResNet\n",
    "\n",
    "\n",
    "device=\"cuda:0\"\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find 4 best models\n",
    "\n",
    "* Is there anything better about using their standard dataloaders rather than the way I did it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN0.t7\n",
      "Testing model :  0\n",
      "Loss: 0.0046 Acc: 0.9601\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN1.t7\n",
      "Testing model :  1\n",
      "Loss: 0.0046 Acc: 0.9600\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN2.t7\n",
      "Testing model :  2\n",
      "Loss: 0.0046 Acc: 0.9614\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN3.t7\n",
      "Testing model :  3\n",
      "Loss: 0.0048 Acc: 0.9600\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN4.t7\n",
      "Testing model :  4\n",
      "Loss: 0.0046 Acc: 0.9600\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN5.t7\n",
      "Testing model :  5\n",
      "Loss: 0.0045 Acc: 0.9612\n"
     ]
    }
   ],
   "source": [
    "# add directory for the wide resnet\n",
    "sys.path.append('/media/rene/code/wide-resnet.pytorch')\n",
    "from networks import *\n",
    "\n",
    "save_path = '/media/rene/data/cifar-10-batches-py/wide-RN-models'\n",
    "num_workers = 4\n",
    "batch_size=32\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                   valid_name='valid')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "results = {}\n",
    "\n",
    "for i in range(6):\n",
    "    model_name = 'wideRN'+str(i)+'.t7'\n",
    "    model = Wide_ResNet(28, 20, 0, 10)\n",
    "    device=\"cuda:1\"\n",
    "    model = model.to(device).eval()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_path = os.path.join(save_path, model_name)\n",
    "    print(model_path)\n",
    "    model.load_state_dict(torch.load(model_path)['net'].state_dict())\n",
    "\n",
    "    print('Testing model : ', i)\n",
    "    valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "    results[model_name] = [valid_acc]\n",
    "    \n",
    "f = open(os.path.join(save_path, \"wideRN_al68.pkl\"),\"wb\")\n",
    "pickle.dump(results,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wideRN2.t7', 0.9614), ('wideRN5.t7', 0.9612), ('wideRN0.t7', 0.9601), ('wideRN1.t7', 0.96), ('wideRN3.t7', 0.96), ('wideRN4.t7', 0.96)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "results2 = {key:value[0] for (key,value) in results.items()}\n",
    "sorted_x = sorted(results2.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(sorted_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN2.t7\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN5.t7\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN0.t7\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN1.t7\n",
      "Loss: 0.0227 Acc: 0.9687\n",
      "Fusion2_WRN_1:  0.02274664867669344 0.9687\n",
      "Loss: 0.0180 Acc: 0.9672\n",
      "Fusion2_WRN_2:  0.017988840979337693 0.9672\n"
     ]
    }
   ],
   "source": [
    "save_path =  Path(PATH / 'cifar-10-batches-py' / 'wide-RN-models')\n",
    "\n",
    "model_name_list = ['wideRN2.t7', 'wideRN5.t7', 'wideRN0.t7', 'wideRN1.t7']\n",
    "num_workers = 6\n",
    "batch_size = 8\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                   valid_name='valid')\n",
    "\n",
    "pretrained_model_list = []\n",
    "for i, model_name in enumerate(model_name_list):\n",
    "    model = Wide_ResNet(28, 20, 0, 10)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_path = os.path.join(save_path, model_name)\n",
    "    print(model_path)\n",
    "    model.load_state_dict(torch.load(model_path)['net'].state_dict())\n",
    "    pretrained_model_list.append(model)\n",
    "    \n",
    "model = Fusion2(pretrained_model_list, num_input=40, num_output=10)\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_WRN_1')))\n",
    "model = model.to(device)\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "print('Fusion2_WRN_1: ', valid_loss, valid_acc)\n",
    "\n",
    "model = Fusion2(pretrained_model_list, num_input=40, num_output=10)\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_WRN_2')))\n",
    "model = model.to(device)\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Fusion2_WRN_2: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Wide ResNet\n",
    "https://github.com/xternalz/WideResNet-pytorch.git\n",
    "\n",
    "source WM/bin/activate\n",
    "python train.py --dataset cifar10 --layers 28 --widen-factor 20\n",
    "(just delete the tensoerboard logger, add print statement to see where saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Loss: 0.0044 Acc: 0.9650\n",
      "valid_acc: 0.965\n"
     ]
    }
   ],
   "source": [
    "# add directory for the wide resnet\n",
    "sys.path.append('/media/rene/code/WideResNet-pytorch')\n",
    "from wideresnet import WideResNet\n",
    "\n",
    "save_path = '/media/rene/code/WideResNet-pytorch/runs/WideResNet-28-10'\n",
    "PATH = '/media/rene/data'\n",
    "num_workers = 4\n",
    "batch_size=32\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                 std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root=PATH, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_name = 'model_best.pth.tar'\n",
    "model = WideResNet(28, 10, 20, dropRate=0)\n",
    "model = model.to(device)\n",
    "\n",
    "# Handle the data parallel\n",
    "\n",
    "# original saved file with DataParallel\n",
    "state_dict = torch.load(os.path.join(save_path, model_name))['state_dict']\n",
    "# create new OrderedDict that does not contain `module.`\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "# load params\n",
    "model.load_state_dict(new_state_dict)\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, testloader, len(testset), criterion, device=device)\n",
    "print('valid_acc:', valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WM",
   "language": "python",
   "name": "wm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
