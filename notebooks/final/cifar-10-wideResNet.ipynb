{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide ResNet\n",
    "From: https://github.com/meliketoy/wide-resnet.pytorch/blob/master/networks/wide_resnet.py\n",
    "\n",
    "Just altered the training script to take different save dir\n",
    "The requirements.txt is incorrect, will just havr to guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/rene/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/rene/code/idc/src\n",
      "2\n",
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import imshow\n",
    "# from IPython.display import display, HTML\n",
    "from collections import OrderedDict\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, densenet121\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "PATH = Path('/media/rene/data')\n",
    "\n",
    "# Add the src directory for functions\n",
    "src_dir = Path.cwd().parent.parent / 'src'\n",
    "print(src_dir)\n",
    "sys.path.append(str(src_dir))\n",
    "sys.path.append('/media/rene/code/wide-resnet.pytorch')\n",
    "\n",
    "\n",
    "# import my functions:\n",
    "from utils import make_cfiar10\n",
    "from functions import*\n",
    "from models import*\n",
    "from networks import Wide_ResNet\n",
    "\n",
    "\n",
    "device=torch.device(\"cuda:1\")\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find 4 best models\n",
    "\n",
    "* Is there anything better about using their standard dataloaders rather than the way I did it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN0.t7\n",
      "Testing model :  0\n",
      "Loss: 0.0046 Acc: 0.9601\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN1.t7\n",
      "Testing model :  1\n",
      "Loss: 0.0046 Acc: 0.9600\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN2.t7\n",
      "Testing model :  2\n",
      "Loss: 0.0046 Acc: 0.9614\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN3.t7\n",
      "Testing model :  3\n",
      "Loss: 0.0048 Acc: 0.9600\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN4.t7\n",
      "Testing model :  4\n",
      "Loss: 0.0046 Acc: 0.9600\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN5.t7\n",
      "Testing model :  5\n",
      "Loss: 0.0045 Acc: 0.9612\n"
     ]
    }
   ],
   "source": [
    "# add directory for the wide resnet\n",
    "sys.path.append('/media/rene/code/wide-resnet.pytorch')\n",
    "from networks import *\n",
    "\n",
    "save_path = '/media/rene/data/cifar-10-batches-py/wide-RN-models'\n",
    "num_workers = 4\n",
    "batch_size=32\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                   valid_name='valid')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "results = {}\n",
    "\n",
    "for i in range(6):\n",
    "    model_name = 'wideRN'+str(i)+'.t7'\n",
    "    model = Wide_ResNet(28, 20, 0, 10)\n",
    "    device=\"cuda:1\"\n",
    "    model = model.to(device).eval()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_path = os.path.join(save_path, model_name)\n",
    "    print(model_path)\n",
    "    model.load_state_dict(torch.load(model_path)['net'].state_dict())\n",
    "\n",
    "    print('Testing model : ', i)\n",
    "    valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "    results[model_name] = [valid_acc]\n",
    "    \n",
    "f = open(os.path.join(save_path, \"wideRN_al68.pkl\"),\"wb\")\n",
    "pickle.dump(results,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('wideRN2.t7', 0.9614), ('wideRN5.t7', 0.9612), ('wideRN0.t7', 0.9601), ('wideRN1.t7', 0.96), ('wideRN3.t7', 0.96), ('wideRN4.t7', 0.96)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "results2 = {key:value[0] for (key,value) in results.items()}\n",
    "sorted_x = sorted(results2.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(sorted_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN2.t7\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN5.t7\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN0.t7\n",
      "| Wide-Resnet 28x20\n",
      "/media/rene/data/cifar-10-batches-py/wide-RN-models/wideRN1.t7\n",
      "Loss: 0.0227 Acc: 0.9687\n",
      "Fusion2_WRN_1:  0.02274664867669344 0.9687\n",
      "Loss: 0.0180 Acc: 0.9672\n",
      "Fusion2_WRN_2:  0.017988840979337693 0.9672\n"
     ]
    }
   ],
   "source": [
    "save_path =  Path(PATH / 'cifar-10-batches-py' / 'wide-RN-models')\n",
    "\n",
    "model_name_list = ['wideRN2.t7', 'wideRN5.t7', 'wideRN0.t7', 'wideRN1.t7']\n",
    "num_workers = 6\n",
    "batch_size = 8\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                   valid_name='valid')\n",
    "\n",
    "pretrained_model_list = []\n",
    "for i, model_name in enumerate(model_name_list):\n",
    "    model = Wide_ResNet(28, 20, 0, 10)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_path = os.path.join(save_path, model_name)\n",
    "    print(model_path)\n",
    "    model.load_state_dict(torch.load(model_path)['net'].state_dict())\n",
    "    pretrained_model_list.append(model)\n",
    "    \n",
    "model = Fusion2(pretrained_model_list, num_input=40, num_output=10)\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_WRN_1')))\n",
    "model = model.to(device)\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "print('Fusion2_WRN_1: ', valid_loss, valid_acc)\n",
    "\n",
    "model = Fusion2(pretrained_model_list, num_input=40, num_output=10)\n",
    "model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_WRN_2')))\n",
    "model = model.to(device)\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Fusion2_WRN_2: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Wide ResNet\n",
    "https://github.com/xternalz/WideResNet-pytorch.git\n",
    "\n",
    "source WM/bin/activate\n",
    "python train.py --dataset cifar10 --layers 28 --widen-factor 20\n",
    "(just delete the tensoerboard logger, add print statement to see where saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "loading:  /media/rene/code/WideResNet-pytorch/runs/WideResNet-28-10_0\n",
      "model was saved as DataParallel\n",
      "Loss: 0.0044 Acc: 0.9650\n",
      "valid_acc: 0.965\n",
      "loading:  /media/rene/code/WideResNet-pytorch/runs/WideResNet-28-10_1\n",
      "Loss: 0.0048 Acc: 0.9622\n",
      "valid_acc: 0.9622\n",
      "loading:  /media/rene/code/WideResNet-pytorch/runs/WideResNet-28-10_2\n",
      "Loss: 0.0045 Acc: 0.9622\n",
      "valid_acc: 0.9622\n",
      "loading:  /media/rene/code/WideResNet-pytorch/runs/WideResNet-28-10_3\n",
      "Loss: 0.0049 Acc: 0.9620\n",
      "valid_acc: 0.962\n",
      "loading:  /media/rene/code/WideResNet-pytorch/runs/WideResNet-28-10_4\n",
      "Loss: 0.0045 Acc: 0.9641\n",
      "valid_acc: 0.9641\n",
      "loading:  /media/rene/code/WideResNet-pytorch/runs/WideResNet-28-10_5\n",
      "Loss: 0.0044 Acc: 0.9636\n",
      "valid_acc: 0.9636\n",
      "{'0': [0.965], '1': [0.9622], '2': [0.9622], '3': [0.962], '4': [0.9641], '5': [0.9636]}\n"
     ]
    }
   ],
   "source": [
    "# add directory for the wide resnet\n",
    "sys.path.append('/media/rene/code/WideResNet-pytorch')\n",
    "from wideresnet import WideResNet\n",
    "\n",
    "PATH = '/media/rene/data'\n",
    "num_workers = 4\n",
    "batch_size=32\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                 std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root=PATH, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_name = 'model_best.pth.tar'\n",
    "model = WideResNet(28, 10, 20, dropRate=0)\n",
    "model = model.to(device)\n",
    "\n",
    "results = {}\n",
    "for i in range(6):\n",
    "    save_path = '/media/rene/code/WideResNet-pytorch/runs/WideResNet-28-10_'+str(i)\n",
    "    print('loading: ', save_path)\n",
    "\n",
    "    # original saved file with DataParallel\n",
    "    state_dict = torch.load(os.path.join(save_path, model_name))['state_dict']\n",
    "    \n",
    "    # Different config if it was trainied with DataParallel\n",
    "    if i ==0:\n",
    "        print('model was saved as DataParallel')\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state_dict.items():\n",
    "            name = k[7:] # remove `module.`\n",
    "            new_state_dict[name] = v\n",
    "        # load params\n",
    "        model.load_state_dict(new_state_dict)\n",
    "    else:\n",
    "        model.load_state_dict(state_dict)\n",
    "        \n",
    "    valid_loss, valid_acc = eval_model(model, testloader, len(testset), criterion, device=device)\n",
    "    print('valid_acc:', valid_acc)\n",
    "\n",
    "    results[str(i)] = [valid_acc]\n",
    "    \n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "------------loading model:  WideResNet-28-10_2/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_3/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_4/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_5/model_best.pth.tar\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/media/rene/code/WideResNet-pytorch')\n",
    "from wideresnet import WideResNet\n",
    "\n",
    "PATH = Path('/media/rene/data/')\n",
    "save_path = Path('/media/rene/code/WideResNet-pytorch/runs')\n",
    "model_name_list = ['WideResNet-28-10_0/model_best.pth.tar', 'WideResNet-28-10_1/model_best.pth.tar', 'WideResNet-28-10_2/model_best.pth.tar', \n",
    "                   'WideResNet-28-10_3/model_best.pth.tar', 'WideResNet-28-10_4/model_best.pth.tar', 'WideResNet-28-10_5/model_best.pth.tar']\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                    valid_name='valid')\n",
    "\n",
    "pretrained_model_list = []\n",
    "# First trained model was with DATA PARALLEL\n",
    "model = WideResNet(28, 10, 20)\n",
    "model = model.to(device)\n",
    "# state_dict = torch.load(os.path.join(save_path, 'WideResNet-28-10_0/model_best.pth.tar'))['state_dict']\n",
    "\n",
    "# # create new OrderedDict that does not contain `module.`\n",
    "# new_state_dict = OrderedDict()\n",
    "# for k, v in state_dict.items():\n",
    "#     name = k[7:] # remove `module.`\n",
    "#     new_state_dict[name] = v\n",
    "# model.load_state_dict(new_state_dict)\n",
    "\n",
    "# pretrained_model_list.append(model)\n",
    "\n",
    "# get all the models\n",
    "for i, model_name in enumerate(model_name_list[2:]):\n",
    "    print('------------loading model: ', model_name)\n",
    "    model = WideResNet(28, 10, 20)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # original saved file with DataParallel\n",
    "    state_dict = torch.load(os.path.join(save_path, model_name))['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "    pretrained_model_list.append(model)\n",
    "\n",
    "model = Fusion2(pretrained_model_list, num_input=60, num_output=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0525 Acc: 0.9558\n",
      "Fusion6_WRN_1:  0.05246691736280918 0.9558\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join('/media/rene/code/WideResNet-pytorch/runs/Fusion6_WRN_1')))\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "print('Fusion6_WRN_1: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0461 Acc: 0.9620\n",
      "Fusion4_WRN_1:  0.04608403277993202 0.962\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join('/media/rene/code/WideResNet-pytorch/runs/Fusion4_WRN_1')))\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "print('Fusion4_WRN_1: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAST ATTEMPT\n",
    "* 4 networks\n",
    "* Only fine tuning the last added layer\n",
    "* ~100 epochs, so should've worked\n",
    "* Had trained using the wrong normalization, comparing the two below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "------------loading model:  WideResNet-28-10_2/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_3/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_4/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_5/model_best.pth.tar\n",
      "Loss: 0.0434 Acc: 0.9611\n",
      "fusionWRN_last4_1:  0.043354870277643204 0.9611\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/media/rene/code/WideResNet-pytorch')\n",
    "from wideresnet import WideResNet\n",
    "\n",
    "with torch.cuda.device(1):\n",
    "    PATH = Path('/media/rene/data/')\n",
    "    save_path = Path('/media/rene/code/WideResNet-pytorch/runs')\n",
    "    model_name_list = ['WideResNet-28-10_0/model_best.pth.tar', 'WideResNet-28-10_1/model_best.pth.tar', 'WideResNet-28-10_2/model_best.pth.tar', \n",
    "                       'WideResNet-28-10_3/model_best.pth.tar', 'WideResNet-28-10_4/model_best.pth.tar', 'WideResNet-28-10_5/model_best.pth.tar']\n",
    "    batch_size = 4\n",
    "    num_workers = 4\n",
    "\n",
    "    dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                        valid_name='valid', transformation=None)\n",
    "\n",
    "    pretrained_model_list = []\n",
    "    for i, model_name in enumerate(model_name_list[2:]):\n",
    "        print('------------loading model: ', model_name)\n",
    "        model = WideResNet(28, 10, 20)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # original saved file with DataParallel\n",
    "        state_dict = torch.load(os.path.join(save_path, model_name))['state_dict']\n",
    "        model.load_state_dict(state_dict)\n",
    "        pretrained_model_list.append(model)\n",
    "\n",
    "    model = Fusion2(pretrained_model_list, num_input=60, num_output=10).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join('/media/rene/code/WideResNet-pytorch/runs/fusionWRN_last4_1')))\n",
    "\n",
    "    valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "    print('fusionWRN_last4_1: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "------------loading model:  WideResNet-28-10_2/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_3/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_4/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_5/model_best.pth.tar\n",
      "Loss: 0.0351 Acc: 0.9686\n",
      "fusionWRN_last4_1:  0.03512242842018604 0.9686\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/media/rene/code/WideResNet-pytorch')\n",
    "from wideresnet import WideResNet\n",
    "\n",
    "PATH = Path('/media/rene/data/')\n",
    "save_path = Path('/media/rene/code/WideResNet-pytorch/runs')\n",
    "model_name_list = ['WideResNet-28-10_0/model_best.pth.tar', 'WideResNet-28-10_1/model_best.pth.tar', 'WideResNet-28-10_2/model_best.pth.tar', \n",
    "                   'WideResNet-28-10_3/model_best.pth.tar', 'WideResNet-28-10_4/model_best.pth.tar', 'WideResNet-28-10_5/model_best.pth.tar']\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                 std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "])\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                    valid_name='valid', transformation=transform_test)\n",
    "\n",
    "pretrained_model_list = []\n",
    "for i, model_name in enumerate(model_name_list[2:]):\n",
    "    print('------------loading model: ', model_name)\n",
    "    model = WideResNet(28, 10, 20)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # original saved file with DataParallel\n",
    "    state_dict = torch.load(os.path.join(save_path, model_name))['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "    pretrained_model_list.append(model)\n",
    "\n",
    "model = Fusion2(pretrained_model_list, num_input=60, num_output=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join('/media/rene/code/WideResNet-pytorch/runs/fusionWRN_last4_1')))\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "print('fusionWRN_last4_1: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average predictions of N networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "------------loading model:  WideResNet-28-10_1/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_2/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_3/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_4/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_5/model_best.pth.tar\n"
     ]
    }
   ],
   "source": [
    "# get all the models:\n",
    "sys.path.append('/media/rene/code/WideResNet-pytorch')\n",
    "from wideresnet import WideResNet\n",
    "\n",
    "save_path = Path('/media/rene/code/WideResNet-pytorch/runs')\n",
    "model_name_list = ['WideResNet-28-10_0/model_best.pth.tar', 'WideResNet-28-10_1/model_best.pth.tar', 'WideResNet-28-10_2/model_best.pth.tar', \n",
    "                   'WideResNet-28-10_3/model_best.pth.tar', 'WideResNet-28-10_4/model_best.pth.tar', 'WideResNet-28-10_5/model_best.pth.tar']\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                 std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "])\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                    valid_name='valid', transformation=transform_test)\n",
    "\n",
    "pretrained_model_list = []\n",
    "\n",
    "# One with with DATA PARALLEL:\n",
    "model = WideResNet(28, 10, 20)\n",
    "model = model.to(device)\n",
    "state_dict = torch.load(os.path.join(save_path, 'WideResNet-28-10_0/model_best.pth.tar'))['state_dict']\n",
    "\n",
    "# create new OrderedDict that does not contain `module.`\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "model.load_state_dict(new_state_dict)\n",
    "pretrained_model_list.append(model)\n",
    "\n",
    "# get all the models\n",
    "for i, model_name in enumerate(model_name_list[1:]):\n",
    "    print('------------loading model: ', model_name)\n",
    "    model = WideResNet(28, 10, 20)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # original saved file with DataParallel\n",
    "    state_dict = torch.load(os.path.join(save_path, model_name))['state_dict']\n",
    "    model.load_state_dict(state_dict)\n",
    "    pretrained_model_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_list_preds(model_list, dataloader):\n",
    "    results = pd.DataFrame()\n",
    "\n",
    "    for (inputs, labels) in dataloader:\n",
    "        inputs = Variable(inputs.cuda())\n",
    "        labels = Variable(labels.cuda())\n",
    "        \n",
    "        output_dict = {}\n",
    "        output_dict['label'] = labels.item()\n",
    "        \n",
    "        for i, model in enumerate(model_list):\n",
    "            model.eval()\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            preds = preds.item()\n",
    "            name = 'model_'+str(i)\n",
    "            output_dict[name] = preds\n",
    "            del outputs \n",
    "        results = results.append(output_dict, ignore_index=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "num_workers = 4\n",
    "PATH = Path('/media/rene/data/')\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                 std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "])\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                    valid_name='valid', transforms=transform_test)\n",
    "\n",
    "results = get_model_list_preds(pretrained_model_list, dataloaders['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965\n",
      "0.9622\n",
      "0.9622\n",
      "0.962\n",
      "0.9641\n",
      "0.9636\n"
     ]
    }
   ],
   "source": [
    "acc = len(results[results['label']==results['model_0']])/len(results)\n",
    "print(acc)\n",
    "acc = len(results[results['label']==results['model_1']])/len(results)\n",
    "print(acc)\n",
    "acc = len(results[results['label']==results['model_2']])/len(results)\n",
    "print(acc)\n",
    "acc = len(results[results['label']==results['model_3']])/len(results)\n",
    "print(acc)\n",
    "acc = len(results[results['label']==results['model_4']])/len(results)\n",
    "print(acc)\n",
    "acc = len(results[results['label']==results['model_5']])/len(results)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader, dataset_size, criterion, device=\"cuda:0\"):\n",
    "    model.train(False)  # Set model to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    # Iterate over data.\n",
    "    for batch_idx, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)   \n",
    "\n",
    "        # forward\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # for nets that have multiple outputs such as inception\n",
    "        if isinstance(outputs, tuple):\n",
    "            loss = sum((criterion(o,labels) for o in outputs))\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        _, preds = outputs.max(1)\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)    \n",
    "    del _, loss, outputs, preds, labels, inputs\n",
    "\n",
    "    epoch_loss = running_loss / dataset_size\n",
    "    epoch_acc = running_corrects / dataset_size\n",
    "    print('Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Loss: 0.1442 Acc: 0.9622\n",
      "WideResNet:  0.1441868129134178 0.9622\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/media/rene/code/WideResNet-pytorch')\n",
    "from wideresnet import WideResNet\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 4\n",
    "PATH = Path('/media/rene/data/')\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                 std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "])\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                    valid_name='valid', transforms=transform_test)\n",
    "model = WideResNet(28, 10, 20)\n",
    "model = model.to(device)\n",
    "\n",
    "save_path = '/media/rene/code/WideResNet-pytorch/runs/'\n",
    "model_name = 'WideResNet-28-10_2/model_best.pth.tar'\n",
    "\n",
    "state_dict = torch.load(os.path.join(save_path, model_name))['state_dict']\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "print('WideResNet: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final - using proper normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/media/rene/code/WideResNet-pytorch')\n",
    "from wideresnet import WideResNet\n",
    "\n",
    "with torch.cuda.device(1):\n",
    "    PATH = Path('/media/rene/data/')\n",
    "    save_path = Path('/media/rene/code/WideResNet-pytorch/runs')\n",
    "    model_name_list = ['WideResNet-28-10_0/model_best.pth.tar', 'WideResNet-28-10_1/model_best.pth.tar', 'WideResNet-28-10_2/model_best.pth.tar', \n",
    "                       'WideResNet-28-10_3/model_best.pth.tar', 'WideResNet-28-10_4/model_best.pth.tar', 'WideResNet-28-10_5/model_best.pth.tar']\n",
    "    batch_size = 4\n",
    "    num_workers = 4\n",
    "\n",
    "    dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                        valid_name='valid', transformation=None)\n",
    "\n",
    "    pretrained_model_list = []\n",
    "    for i, model_name in enumerate(model_name_list[1:3]):\n",
    "        print('------------loading model: ', model_name)\n",
    "        model = WideResNet(28, 10, 20)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # original saved file with DataParallel\n",
    "        state_dict = torch.load(os.path.join(save_path, model_name))['state_dict']\n",
    "        model.load_state_dict(state_dict)\n",
    "        pretrained_model_list.append(model)\n",
    "\n",
    "    model = Fusion2(pretrained_model_list, num_input=60, num_output=10).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(os.path.join('/media/rene/code/WideResNet-pytorch/runs/fusionWRN_last4_1')))\n",
    "\n",
    "    valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "    print('fusionWRN_last4_1: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "------------loading model:  WideResNet-28-10_1/model_best.pth.tar\n",
      "------------loading model:  WideResNet-28-10_2/model_best.pth.tar\n",
      "Loss: 0.0082 Acc: 0.9697\n",
      "fusionWRN_last3_1 0.008204502047598362 0.9697\n",
      "Loss: 0.0083 Acc: 0.9699\n",
      "fusionWRN_last3_2 0.008345628140866757 0.9699\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/media/rene/code/WideResNet-pytorch')\n",
    "from wideresnet import WideResNet\n",
    "\n",
    "with torch.cuda.device(1):\n",
    "    PATH = Path('/media/rene/data/')\n",
    "    save_path = Path('/media/rene/code/WideResNet-pytorch/runs')\n",
    "    model_name_list = ['WideResNet-28-10_0/model_best.pth.tar', 'WideResNet-28-10_1/model_best.pth.tar', 'WideResNet-28-10_2/model_best.pth.tar', \n",
    "                       'WideResNet-28-10_3/model_best.pth.tar', 'WideResNet-28-10_4/model_best.pth.tar', 'WideResNet-28-10_5/model_best.pth.tar']\n",
    "    batch_size = 16\n",
    "    num_workers = 4\n",
    "\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[x/255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                     std=[x/255.0 for x in [63.0, 62.1, 66.7]])\n",
    "    ])\n",
    "    dataloaders, dataset_sizes = make_batch_gen_cifar(str(PATH), batch_size, num_workers,\n",
    "                                                        valid_name='valid', transformation=transform_test)\n",
    "\n",
    "    pretrained_model_list = []\n",
    "    # First trained model was with DATA PARALLEL\n",
    "    model = WideResNet(28, 10, 20)\n",
    "    model = model.to(device)\n",
    "\n",
    "    state_dict = torch.load(os.path.join(save_path, 'WideResNet-28-10_0/model_best.pth.tar'))['state_dict']\n",
    "\n",
    "    # create new OrderedDict that does not contain `module.`\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        name = k[7:] # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    pretrained_model_list.append(model)\n",
    "\n",
    "    # get all the models\n",
    "    for i, model_name in enumerate(model_name_list[1:3]):\n",
    "        print('------------loading model: ', model_name)\n",
    "        model = WideResNet(28, 10, 20)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # original saved file with DataParallel\n",
    "        state_dict = torch.load(os.path.join(save_path, model_name))['state_dict']\n",
    "        model.load_state_dict(state_dict)\n",
    "        pretrained_model_list.append(model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model = Fusion3(pretrained_model_list, num_input=30, num_output=10).to(device)\n",
    "    \n",
    "    model.load_state_dict(torch.load(os.path.join('/media/rene/code/WideResNet-pytorch/runs/fusionWRN_last3_1')))\n",
    "    valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "    print('fusionWRN_last3_1', valid_loss, valid_acc)\n",
    "    \n",
    "    model.load_state_dict(torch.load(os.path.join('/media/rene/code/WideResNet-pytorch/runs/fusionWRN_last3_2')))\n",
    "    valid_loss, valid_acc = eval_model(model, dataloaders['valid'], dataset_sizes['valid'], criterion, device=device)\n",
    "    print('fusionWRN_last3_2', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437447536"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "get_n_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145815514"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n_params(model.model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WM",
   "language": "python",
   "name": "wm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
