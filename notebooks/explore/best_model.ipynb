{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.transforms import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.model import *\n",
    "from fastai.dataset import *\n",
    "from fastai.sgdr import *\n",
    "from fastai.plots import *\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "# from torchvision.models import densenet169, resnext101\n",
    "# from fastai.models.cifar10.wideresnet import wrn_22\n",
    "\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "fast_ai_dir = '/media/rene/Data/fastai/'\n",
    "sys.path.append(fast_ai_dir)\n",
    "\n",
    "# Set it to use GPU1\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/media/rene/Data/data/idc'\n",
    "SAMPLE_PATH = '/media/rene/Data/data/idc/sample'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=256\n",
    "sz=50\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomCrop(sz), RandomFlip()], pad=sz//8)\n",
    "data = ImageClassifierData.from_paths(SAMPLE_PATH, val_name='test', tfms=tfms, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3709f4a807e46e7b3a5df326d83a537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 14/76 [00:10<00:45,  1.36it/s, loss=2.37]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 70/76 [00:44<00:03,  1.57it/s, loss=56.4]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = wrn_22()\n",
    "\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "\n",
    "lrf=learn.lr_find(start_lr=1e-5, end_lr=100)\n",
    "learn.sched.plot(n_skip=5, n_skip_end=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3d338342ec48dcb471a6ec06cfb6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=30), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/76 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.311246   0.325822   0.860644  \n",
      "    1      0.309531   0.324942   0.855598                  \n",
      "    2      0.308903   0.339466   0.855598                  \n",
      "    3      0.303944   0.319762   0.865449                  \n",
      "    4      0.304703   0.320282   0.859683                  \n",
      "    5      0.304927   0.311639   0.867131                  \n",
      "    6      0.301252   0.373033   0.847669                  \n",
      "    7      0.29737    0.317939   0.864728                  \n",
      "    8      0.292391   0.349863   0.844786                  \n",
      "    9      0.289626   0.302695   0.873859                  \n",
      "    10     0.289775   0.309685   0.872417                  \n",
      "    11     0.286811   0.329198   0.87482                   \n",
      "    12     0.283951   0.302301   0.877463                  \n",
      "    13     0.282755   0.34159    0.858962                  \n",
      "    14     0.278303   0.323872   0.86593                   \n",
      "    15     0.273598   0.403924   0.842383                  \n",
      "    16     0.273219   0.298809   0.882268                  \n",
      "    17     0.268492   0.283736   0.885151                  \n",
      "    18     0.26446    0.310992   0.876982                  \n",
      "    19     0.263218   0.290842   0.879625                  \n",
      "    20     0.258654   0.2806     0.889476                  \n",
      "    21     0.258211   0.28528    0.880106                  \n",
      "    22     0.253676   0.285824   0.87506                   \n",
      "    23     0.247723   0.265082   0.887794                  \n",
      "    24     0.24187    0.267075   0.888515                  \n",
      "    25     0.239724   0.263832   0.892359                  \n",
      "    26     0.239988   0.267547   0.891158                  \n",
      "    27     0.234187   0.265825   0.885872                  \n",
      "    28     0.235196   0.262001   0.890678                  \n",
      "    29     0.233413   0.263109   0.890918                  \n",
      "CPU times: user 24min 43s, sys: 7min 39s, total: 32min 23s\n",
      "Wall time: 25min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.26311]), 0.8909178276236157]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=128\n",
    "sz=50\n",
    "lr=.01\n",
    "\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomDihedral()], pad=sz//8)\n",
    "data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs)\n",
    "\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=30, use_clr_beta=(20,20,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=128\n",
    "sz=50\n",
    "lr=.01\n",
    "\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomDihedral()], pad=sz//8)\n",
    "data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs)\n",
    "\n",
    "learn.unfreeze()\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=30, use_clr_beta=(20,20,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=256\n",
    "sz=50\n",
    "lr=.01\n",
    "\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomDihedral()], pad=sz//8)\n",
    "data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs)\n",
    "\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=30, use_clr_beta=(20,20,0.95,0.85))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More normalish sgdr. Still trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4e311243344018a1480383c0a1ed5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 53/3036 [00:10<09:35,  5.18it/s, loss=2.21] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      0.310794   0.298979   0.872973  \n",
      "\n",
      "CPU times: user 9min 17s, sys: 2min 39s, total: 11min 56s\n",
      "Wall time: 9min 38s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7271c46f68f411484ea238d9d8d7369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 56/3036 [00:10<09:04,  5.48it/s, loss=0.315]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      0.289176   0.276343   0.883062  \n",
      "    1      0.28922    0.278334   0.884672                      \n",
      " 23%|██▎       | 712/3036 [02:07<06:56,  5.58it/s, loss=0.277]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m          Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/media/rene/Data/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/rene/Data/fastai/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/rene/Data/fastai/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/rene/Data/fastai/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mcopy_fp32_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/rene/Data/fastai/fastai/model.py\u001b[0m in \u001b[0;36mtorch_item\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtorch_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mStepper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = wrn_22()\n",
    "learn = ConvLearner.from_model_data(m, data)\n",
    "learn.crit = nn.CrossEntropyLoss()\n",
    "learn.metrics = [accuracy]\n",
    "wd=1e-4\n",
    "\n",
    "bs=64\n",
    "sz=50\n",
    "\n",
    "lr=.003\n",
    "\n",
    "stats = (np.array([ 0.4914 ,  0.48216,  0.44653]), np.array([ 0.24703,  0.24349,  0.26159]))\n",
    "\n",
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomDihedral()], pad=sz//8)\n",
    "data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs)\n",
    "\n",
    "%time learn.fit(lr, 1, cycle_len=1, cycle_mult=1) # train last few layers\n",
    "lrs = np.array([lr/4,lr/2,lr])\n",
    "\n",
    "learn.unfreeze()\n",
    "%time learn.fit(lr, 3, cycle_len=1, cycle_mult=2, best_save_name='wideRes_sgdr') # train whole model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained DenseNet, ResNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb17b0195ee34d81a4bfa8e2a021d165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/608 [00:06<05:13,  1.90it/s, loss=0.952]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.338761   0.301821   0.878184  \n",
      "    1      0.364903   0.333011   0.859683                    \n",
      "    2      0.331145   0.320073   0.867371                    \n",
      "    3      0.325843   0.319195   0.870495                    \n",
      "    4      0.312231   0.302981   0.873138                    \n",
      "    5      0.291791   0.295174   0.879145                    \n",
      "    6      0.290758   0.29114    0.879625                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.29114]), 0.879625180201826]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = 224\n",
    "bs = 32\n",
    "arch = resnext101\n",
    "\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_top_down, max_zoom=1)\n",
    "data = ImageClassifierData.from_paths(SAMPLE_PATH, tfms=tfms, bs=bs)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=False)\n",
    "\n",
    "lr =.001\n",
    "# learn.fit(lr, 1, cycle_len=1, cycle_mult=1) # train last few layers\n",
    "lrs = np.array([lr/4,lr/2,lr])\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs, 3, cycle_len=1, cycle_mult=2, best_save_name='resnext101_1') # train whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37d781e8d5649099601e2f5c939af65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 83/608 [00:05<00:32, 16.28it/s, loss=0.683]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rene/miniconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
      "  TqdmSynchronisationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.424146   0.400868   0.826526  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab468cf646fe4117b744bea5de621844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                    \n",
      "    0      0.358446   0.346883   0.85728   \n",
      "    1      0.361325   0.357479   0.851033                    \n",
      "    2      0.361008   0.352885   0.852235                    \n",
      "    3      0.366869   0.34273    0.858481                    \n",
      "    4      0.32977    0.328921   0.864008                    \n",
      "    5      0.334218   0.331093   0.857761                    \n",
      "    6      0.317302   0.32956    0.863767                    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.32956]), 0.863767419509851]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = 50\n",
    "bs = 32\n",
    "arch = resnext101\n",
    "\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_top_down, max_zoom=1)\n",
    "data = ImageClassifierData.from_paths(SAMPLE_PATH, tfms=tfms, bs=bs)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=False)\n",
    "\n",
    "lr =.001\n",
    "learn.fit(lr, 1, cycle_len=1, cycle_mult=1) # train last few layers\n",
    "lrs = np.array([lr/4,lr/2,lr])\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs, 3, cycle_len=1, cycle_mult=2, best_save_name='resnext101_2') # train whole model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seems that using the original sized input for these models is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture out1\n",
    "\n",
    "sz = 224\n",
    "bs = 32\n",
    "arch = resnext101\n",
    "\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_top_down, max_zoom=1)\n",
    "data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=bs)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=False)\n",
    "\n",
    "lr =.001\n",
    "learn.fit(lr, 1, cycle_len=1, cycle_mult=1) # train last few layers\n",
    "lrs = np.array([lr/4,lr/2,lr])\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs, 3, cycle_len=1, cycle_mult=2, best_save_name='resnext101_1_full') # train whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18409a1752734d948e501e444fc9da1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3886 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# ??? This won't work. just crashes\n",
    "sz = 224\n",
    "bs = 5\n",
    "arch = densenet169\n",
    "\n",
    "tfms = tfms_from_model(arch, sz, aug_tfms=transforms_top_down, max_zoom=1)\n",
    "data = ImageClassifierData.from_paths(SAMPLE_PATH, tfms=tfms, bs=bs)\n",
    "learn = ConvLearner.pretrained(arch, data, precompute=False)\n",
    "\n",
    "lr =.003\n",
    "learn.fit(lr, 1, cycle_len=1, cycle_mult=1) # train last few layers\n",
    "lrs = np.array([lr/4,lr/2,lr])\n",
    "learn.unfreeze()\n",
    "learn.fit(lrs, 3, cycle_len=1, cycle_mult=2, best_save_name='densenet169_1') # train whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ??? Check if cropping is useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(stats, sz, aug_tfms=[RandomCrop(sz), RandomDihedral()], pad=sz//8)\n",
    "data = ImageClassifierData.from_paths(PATH, val_name='test', tfms=tfms, bs=bs)\n",
    "\n",
    "\n",
    "%time learn.fit(lr, 1, wds=wd, cycle_len=10, use_clr_beta=(20,20,0.95,0.85))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
