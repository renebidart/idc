{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning 3 resnet 34 fusion model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rene/code/idc/src\n",
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torchvision.models import resnet34\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_PATH = Path('/home/rene/data/idc')\n",
    "\n",
    "# Add the src directory for functions\n",
    "src_dir = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), 'src')\n",
    "print(src_dir)\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my functions:\n",
    "from functions import*\n",
    "from models import*\n",
    "\n",
    "# torch.cuda.set_device(1)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion 1 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name_list = ['resnet34_0', 'resnet34_5', 'resnet34_2']\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 6\n",
    "save_path = '/media/rene/Data/data/idc/models'\n",
    "PATH = '/media/rene/Data/data/idc'\n",
    "input_size = 6\n",
    "\n",
    "pretrained_model_list = []\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name_list[idx])))\n",
    "    pretrained_model_list.append(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4197 Acc: 0.8521\n",
      "Validation Fusion1_1:  0.4196543438838542 0.8521463402916236\n",
      "Loss: 0.4202 Acc: 0.8528\n",
      "Test Fusion1_1:  0.4201910931596171 0.8527949266136587\n"
     ]
    }
   ],
   "source": [
    "dataloaders, dataset_sizes= make_batch_gen(PATH, batch_size, num_workers, \n",
    "                                                        valid_name='valid', test_name='test', size=197)\n",
    "\n",
    "fusion_model = Fusion1Hardcode(pretrained_model_list)\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion1_1')))\n",
    "batch_size = 8\n",
    "num_workers = 6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model_ft, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Validation Fusion1_1: ', valid_loss, valid_acc)\n",
    "\n",
    "test_loss, test_acc = eval_model(model_ft, dataloaders['test'], dataset_sizes['test'], criterion)\n",
    "print('Test Fusion1_1: ' , test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion 2 stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2222 Acc: 0.9092\n",
      "Validation Fusion2_2s2-test-full-data:  0.22221683784354648 0.9092219366307142\n",
      "Loss: 0.2222 Acc: 0.9092\n",
      "Validation Fusion2_2s2-test-full-data:  0.22221683610533421 0.9092219366307142\n"
     ]
    }
   ],
   "source": [
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name_list = ['resnet34_0', 'resnet34_5', 'resnet34_2']\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 6\n",
    "input_size = 6\n",
    "\n",
    "# save_path = '/media/rene/Data/data/idc/models'\n",
    "# PATH = '/media/rene/Data/data/idc'\n",
    "save_path =  Path(DATA_PATH, 'models')\n",
    "PATH = DATA_PATH\n",
    "\n",
    "pretrained_model_list = []\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name_list[idx])))\n",
    "    pretrained_model_list.append(model_ft)\n",
    "\n",
    "model_ft = Fusion2Hardcode(pretrained_model_list)\n",
    "\n",
    "dataloaders, dataset_sizes= make_batch_gen(PATH, batch_size, num_workers, \n",
    "                                                        valid_name='valid', test_name='test', size=197)\n",
    "\n",
    "fusion_model = Fusion2Hardcode(pretrained_model_list)\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_2s2-test-full-data')))\n",
    "batch_size = 8\n",
    "num_workers = 6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "valid_loss, valid_acc = eval_model(fusion_model, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Validation Fusion2_2s2-test-full-data: ', valid_loss, valid_acc)\n",
    "\n",
    "valid_loss, valid_acc = eval_model(fusion_model, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Validation Fusion2_2s2-test-full-data: ', valid_loss, valid_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity/Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sensitivity: 0.9293772265470379, specificity: 0.8552108194112967, Acc: 0.9092219366307142\n",
      "Test sensitivity: 0.9309866137828459, specificity: 0.851063829787234, Acc: 0.9091498714838214\n"
     ]
    }
   ],
   "source": [
    "all_labels, all_preds = get_preds(fusion_model, dataloaders['valid'], dataset_sizes['valid'])\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Validation sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')\n",
    "\n",
    "all_labels, all_preds = get_preds(fusion_model, dataloaders['test'], dataset_sizes['test'])\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Test sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fusion 2 -test-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name_list = ['resnet34_0', 'resnet34_5', 'resnet34_2']\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 6\n",
    "# save_path = '/media/rene/Data/data/idc/models'\n",
    "# PATH = '/media/rene/Data/data/idc'\n",
    "\n",
    "save_path =  Path(DATA, 'models')\n",
    "PATH = DATA_PATH\n",
    "\n",
    "input_size = 6\n",
    "\n",
    "pretrained_model_list = []\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name_list[idx])))\n",
    "    pretrained_model_list.append(model_ft)\n",
    "\n",
    "\n",
    "dataloaders, dataset_sizes= make_batch_gen(PATH, batch_size, num_workers, \n",
    "                                                        valid_name='valid', test_name='test', size=197)\n",
    "\n",
    "fusion_model = Fusion2Hardcode(pretrained_model_list)\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_1-test-full-data')))\n",
    "batch_size = 8\n",
    "num_workers = 6\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4888 Acc: 0.8933\n",
      "Validation Fusion2_1:  0.48884277451232083 0.8932955391674073\n",
      "Loss: 0.4832 Acc: 0.8954\n",
      "Test Fusion2_1:  0.4832239666094465 0.8954094501429292\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_acc = eval_model(model_ft, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Validation Fusion2_1: ', valid_loss, valid_acc)\n",
    "\n",
    "test_loss, test_acc = eval_model(model_ft, dataloaders['test'], dataset_sizes['test'], criterion)\n",
    "print('Test Fusion2_1: ' , test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 4D tensor as input, got 2D tensor instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-53fd7537b0b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_preds_fusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfusion_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metrics_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Validation sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_preds_fusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfusion_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_model_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sizes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/rene/Data/idc/src/functions.py\u001b[0m in \u001b[0;36mget_preds_fusion\u001b[0;34m(model, model_list, dataloader, dataset_size)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/rene/Data/idc/src/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 282\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected 4D tensor as input, got {}D tensor instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     f = _ConvNd(_pair(stride), _pair(padding), _pair(dilation), False,\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 4D tensor as input, got 2D tensor instead."
     ]
    }
   ],
   "source": [
    "all_labels, all_preds = get_preds_fusion(fusion_model, pretrained_model_list, dataloaders['valid'], dataset_sizes['valid'])\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Validation sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')\n",
    "\n",
    "all_labels, all_preds = get_preds_fusion(fusion_model, pretrained_model_list, dataloaders['test'], dataset_sizes['test'])\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Test sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useless:::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion 2 Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9721 Acc: 0.5387\n",
      "Validation Fusion2_1:  0.9721003385875616 0.5386833253243632\n",
      "Loss: 0.9684 Acc: 0.5454\n",
      "Test Fusion2_1:  0.9683997267315675 0.545410860163383\n"
     ]
    }
   ],
   "source": [
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name_list = ['resnet34_0', 'resnet34_5', 'resnet34_2']\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 6\n",
    "save_path = '/media/rene/Data/data/idc/models'\n",
    "PATH = '/media/rene/Data/data/idc/sample'\n",
    "\n",
    "\n",
    "pretrained_model_list = []\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name_list[idx])))\n",
    "    pretrained_model_list.append(model_ft)\n",
    "\n",
    "\n",
    "dataloaders, dataset_sizes= make_batch_gen(PATH, batch_size, num_workers, \n",
    "                                                        valid_name='valid', test_name='test', size=197)\n",
    "\n",
    "fusion_model = Fusion2Hardcode(pretrained_model_list)\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_1')))\n",
    "batch_size = 32\n",
    "num_workers = 6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model_ft, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Validation Fusion2_1: ', valid_loss, valid_acc)\n",
    "\n",
    "test_loss, test_acc = eval_model(model_ft, dataloaders['test'], dataset_sizes['test'], criterion)\n",
    "print('Test Fusion2_1: ' , test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name_list = ['resnet34_0', 'resnet34_5', 'resnet34_2']\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 6\n",
    "save_path = '/media/rene/Data/data/idc/models'\n",
    "PATH = '/media/rene/Data/data/idc'\n",
    "input_size = 6\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, \n",
    "                                            valid_name='valid', test_name='test', size=197)\n",
    "\n",
    "pretrained_model_list = []\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name_list[idx])))\n",
    "    pretrained_model_list.append(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders, dataset_sizes= make_batch_gen(PATH, batch_size, num_workers, \n",
    "                                                        valid_name='valid', test_name='test', size=197)\n",
    "\n",
    "fusion_model = Fusion2Hardcode(pretrained_model_list)\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_1')))\n",
    "batch_size = 8\n",
    "num_workers = 6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "valid_loss, valid_acc = eval_model(model_ft, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Validation Fusion2_1: ', valid_loss, valid_acc)\n",
    "\n",
    "test_loss, test_acc = eval_model(model_ft, dataloaders['test'], dataset_sizes['test'], criterion)\n",
    "print('Test Fusion2_1: ' , test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug test/val perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Loss: 0.9601 Acc: 0.5570\n",
      "Validation Fusion2_1:  0.5570155420500132 0.5570155420500132 0.9601346823262482\n",
      "valid Loss: 0.9601 Acc: 0.5570\n",
      "Test Fusion2_1:  0.5570155420500132 0.5570155420500132 0.9601346820728186\n"
     ]
    }
   ],
   "source": [
    "dataloaders, dataset_sizes= make_batch_gen(PATH, batch_size, num_workers, \n",
    "                                                        valid_name='valid', test_name='test', size=197)\n",
    "\n",
    "fusion_model = Fusion2Hardcode(pretrained_model_list)\n",
    "fusion_model = fusion_model.cuda()\n",
    "\n",
    "fusion_model.load_state_dict(torch.load(os.path.join(save_path, 'Fusion2_1')))\n",
    "batch_size = 8\n",
    "num_workers = 6\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "best_acc, epoch_acc, epoch_loss = eval_model_testing(model_ft, criterion, optimizer, scheduler, \n",
    "                                                     dataloaders, dataset_sizes)\n",
    "print('Validation Fusion2_1: ', best_acc, epoch_acc, epoch_loss)\n",
    "\n",
    "best_acc, epoch_acc, epoch_loss = eval_model_testing(model_ft, criterion, optimizer, scheduler, \n",
    "                                                     dataloaders, dataset_sizes)\n",
    "print('Test Fusion2_1: ' , best_acc, epoch_acc, epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels, all_preds = get_preds_fusion(fusion_model, model_list_ft, dataloaders['valid'], dataset_sizes['valid'])\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Validation sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')\n",
    "\n",
    "all_labels, all_preds = get_preds_fusion(fusion_model, model_list_ft, dataloaders['test'], dataset_sizes['test'])\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Test sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
