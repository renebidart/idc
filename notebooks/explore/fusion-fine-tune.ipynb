{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning 3 resnet 34 fusion model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/rene/Data/idc/src\n",
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torchvision.models import resnet34\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "\n",
    "# Add the src directory for functions\n",
    "src_dir = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), 'src')\n",
    "print(src_dir)\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my functions:\n",
    "from functions import*\n",
    "\n",
    "# Set it to use GPU1\n",
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_fusion_model(model_list, model_name_list, save_path, input_size, model=WeightedSum):\n",
    "#     \"\"\"\n",
    "#     model_list: list of model architectures\n",
    "#     model_name_list: list of the names files of model weights\n",
    "    \n",
    "#     \"\"\"\n",
    "#     model_list_ft = []    \n",
    "#     for idx, model_arch in enumerate(model_list):\n",
    "#         # get the proper model architecture\n",
    "#         model_ft = model_arch(pretrained=False)\n",
    "#         num_ftrs = model_ft.fc.in_features\n",
    "#         model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "#         model_ft = model_ft.cuda()\n",
    "#         # load the saved weights\n",
    "#         model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name_list[idx])))\n",
    "#         model_list_ft.append(model_ft)\n",
    "        \n",
    "#     fusion_model = model(num_input=6)\n",
    "#     fusion_model = fusion_model.cuda()\n",
    "#     return model_list_ft, fusion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fusion1(nn.Module):\n",
    "    \"\"\"Take list of models, fuse their output into 2 classes\"\"\"\n",
    "    def __init__(self, model_list):\n",
    "        super(Fusion1, self).__init__()\n",
    "        self.model_list = model_list\n",
    "        self.num_input = int(len(self.model_list)*2)\n",
    "        self.fc = nn.Linear(self.num_input, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for model in model_list:\n",
    "            outputs.append(model(x))\n",
    "        x = torch.cat(outputs, 1)\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "    \n",
    "class Fusion1Hardcode(nn.Module):\n",
    "    \"\"\"Take list of models, fuse their output into 2 classes\"\"\"\n",
    "    def __init__(self, model_list):\n",
    "        super(Fusion1Hardcode, self).__init__()\n",
    "        self.model1 = model_list[0]\n",
    "        self.model2 = model_list[1]\n",
    "        self.model3 = model_list[2]\n",
    "        self.fc = nn.Linear(6, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.model1(x)\n",
    "        x2 = self.model2(x)\n",
    "        x3 = self.model3(x)\n",
    "        x4 = torch.cat((x1, x2, x3), 1)\n",
    "        out = self.fc(x4)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Fusion2(nn.Module):\n",
    "#     \"\"\"FusionModel1 plus extra fc layer after the concat so there is non-linear combination of the outputs \n",
    "#     Take list of models, concat output->16 node fc->output(2 class)\n",
    "#     \"\"\"\n",
    "#     def __init__(self, model_list):\n",
    "#         super(Fusion1, self).__init__()\n",
    "#         self.model_list = model_list\n",
    "#         self.num_input = int(len(self.model_list)*2)\n",
    "#         self.fc1 = nn.Linear(self.num_input, 16)\n",
    "#         self.fc2 = nn.Linear(16, 2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         outputs = []\n",
    "#         for model in model_list:\n",
    "#             outputs.append(model(x))\n",
    "#         x1 = torch.cat(outputs, 1)\n",
    "#         x2 = nn.ReLU(self.fc1(x))\n",
    "#         out = self.fc2(x2)\n",
    "#         return out\n",
    "    \n",
    "class Fusion2Hardcode(nn.Module):\n",
    "    \"\"\"Take list of models, fuse their output into 2 classes\"\"\"\n",
    "    def __init__(self, model_list):\n",
    "        super(Fusion2Hardcode, self).__init__()\n",
    "        self.model1 = model_list[0]\n",
    "        self.model2 = model_list[1]\n",
    "        self.model3 = model_list[2]\n",
    "        self.fc1 = nn.Linear(6, 16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.model1(x)\n",
    "        x2 = self.model2(x)\n",
    "        x3 = self.model3(x)\n",
    "        x4 = torch.cat((x1, x2, x3), 1)\n",
    "        x5 = self.fc1(x4)\n",
    "        x6 = self.relu(x5)\n",
    "        out = self.fc2(x5)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fusion3(nn.Module):\n",
    "    \"\"\"Throw away final classification layer before the concat is done.\n",
    "    More parameters are in merged section of model: moving towards to a single model \n",
    "    Pop last (classification) layer of models, concat output->256 node fc->output(2 class)\n",
    "    \"\"\"\n",
    "    def __init__(self, model_list):\n",
    "        super(Fusion1, self).__init__()\n",
    "        new_models = []\n",
    "        model_ft.fc.in_features = 0\n",
    "        for model in new_models:\n",
    "            model_ft.fc.in_features += model.fc.in_features\n",
    "            modules = list(model.children())[:-1]      # delete the last fc layer.\n",
    "            model = nn.Sequential(*modules)\n",
    "            new_models.append(model)        \n",
    "        \n",
    "        self.model_list = new_models\n",
    "        self.num_input = int(len(self.model_list)*2)\n",
    "        self.fc1 = nn.Linear(num_input, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = []\n",
    "        for model in model_list:\n",
    "            outputs.append(model(x))\n",
    "        x1 = torch.cat(outputs, 1)\n",
    "        x2 = F.relu(self.fc1(x))\n",
    "        out = self.fc2(x2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHeck the model arch that the last layer is actually fc, not a sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Fusion1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [resnet34, resnet34, resnet34]\n",
    "model_name_list = ['resnet34_0', 'resnet34_5', 'resnet34_2']\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 6\n",
    "save_path = '/media/rene/Data/data/idc/models'\n",
    "PATH = '/media/rene/Data/data/idc'\n",
    "input_size = 6\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, \n",
    "                                            valid_name='valid', test_name='test', size=197)\n",
    "\n",
    "pretrained_model_list = []\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name_list[idx])))\n",
    "    pretrained_model_list.append(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture out1\n",
    "epochs = 12\n",
    "model_ft = Fusion1Hardcode(pretrained_model_list)\n",
    "model_ft = model_ft.cuda()\n",
    "model_name = 'Fusion1_1'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                 epochs, dataloaders, dataset_sizes)\n",
    "torch.save(model_ft.state_dict(), os.path.join(save_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/11\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "%%capture cell_output\n",
    "epochs = 12\n",
    "model_ft = Fusion2Hardcode(pretrained_model_list)\n",
    "model_ft = model_ft.cuda()\n",
    "model_name = 'Fusion2_1'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                 epochs, dataloaders, dataset_sizes)\n",
    "torch.save(model_ft.state_dict(), os.path.join(save_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cell_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-816a4f7a1bf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcell_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cell_output' is not defined"
     ]
    }
   ],
   "source": [
    "cell_output.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained\n",
    "* Cat ouptut features and add a fc layer onto the final classification layer, train all the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained\n",
    "* pop the final classification layer, add in cat and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
