{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet 34 and inception v3\n",
    "\n",
    "### ??? Test resnet with image size 224 ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rene/code/idc/src\n",
      "True\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torchvision.models import resnet34, inception_v3\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "# Add the src directory for functions\n",
    "src_dir = os.path.join(os.path.dirname(os.path.dirname(os.getcwd())), 'src')\n",
    "print(src_dir)\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my functions:\n",
    "from functions import*\n",
    "\n",
    "# Set it to use GPU1\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ResNet34 on 10% sample\n",
    "* Upsample the image to 197x197"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/11\n",
      "----------\n",
      "train Loss: 0.3949 Acc: 0.8375\n",
      "valid Loss: 0.3705 Acc: 0.8349\n",
      "Epoch 1/11\n",
      "----------\n",
      "train Loss: 0.3532 Acc: 0.8480\n",
      "valid Loss: 0.4576 Acc: 0.7857\n",
      "Epoch 2/11\n",
      "----------\n",
      "train Loss: 0.3447 Acc: 0.8565\n",
      "valid Loss: 0.3519 Acc: 0.8465\n",
      "Epoch 3/11\n",
      "----------\n",
      "train Loss: 0.3270 Acc: 0.8610\n",
      "valid Loss: 0.3355 Acc: 0.8532\n",
      "Epoch 4/11\n",
      "----------\n",
      "train Loss: 0.3225 Acc: 0.8596\n",
      "valid Loss: 0.3374 Acc: 0.8520\n",
      "Epoch 5/11\n",
      "----------\n",
      "train Loss: 0.3220 Acc: 0.8619\n",
      "valid Loss: 0.3327 Acc: 0.8563\n",
      "Epoch 6/11\n",
      "----------\n",
      "train Loss: 0.3173 Acc: 0.8635\n",
      "valid Loss: 0.3271 Acc: 0.8578\n",
      "Epoch 7/11\n",
      "----------\n",
      "train Loss: 0.3159 Acc: 0.8646\n",
      "valid Loss: 0.3290 Acc: 0.8546\n",
      "Epoch 8/11\n",
      "----------\n",
      "train Loss: 0.3149 Acc: 0.8660\n",
      "valid Loss: 0.3265 Acc: 0.8578\n",
      "Epoch 9/11\n",
      "----------\n",
      "train Loss: 0.3141 Acc: 0.8664\n",
      "valid Loss: 0.3309 Acc: 0.8542\n",
      "Epoch 10/11\n",
      "----------\n",
      "train Loss: 0.3125 Acc: 0.8670\n",
      "valid Loss: 0.3276 Acc: 0.8558\n",
      "Epoch 11/11\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "PATH = '/media/rene/Data/data/idc/sample'\n",
    "num_workers = 6\n",
    "batch_size=64\n",
    "\n",
    "# Is 197 the min size for resnet? this is so ineffecient, the images are 50x50\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid', size=197)\n",
    "\n",
    "model_list = [resnet34]\n",
    "model_name = ['resnet34']\n",
    "\n",
    "epochs = 12\n",
    "save_path = '/media/rene/Data/data/idc/sample/models'\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "    best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     epochs, dataloaders, dataset_sizes)\n",
    "    torch.save(model_ft.state_dict(), os.path.join(save_path, model_name[idx]+'_'+str(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.3556 Acc: 0.8466\n",
      "valid Loss: 0.3326 Acc: 0.8620\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "PATH = '/media/rene/Data/data/idc'\n",
    "num_workers = 6\n",
    "batch_size=64\n",
    "\n",
    "# Is 197 the min size for resnet? this is so ineffecient, the images are 50x50\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid', size=197)\n",
    "\n",
    "model_list = [resnet34, resnet34, resnet34, resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34', 'resnet34', 'resnet34', 'resnet34', 'resnet34', 'resnet34']\n",
    "\n",
    "epochs = 10\n",
    "save_path = '/media/rene/Data/data/idc/models'\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "    best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                     epochs, dataloaders, dataset_sizes)\n",
    "    torch.save(model_ft.state_dict(), os.path.join(save_path, model_name[idx]+'_'+str(idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Model Validation: \n",
      "Loss: 0.3140 Acc: 0.8655\n",
      "Sample Model Test:  resnet34_0\n",
      "Loss: 0.3169 Acc: 0.8628\n"
     ]
    }
   ],
   "source": [
    "model_arch = resnet34\n",
    "model_name = 'resnet34_0'\n",
    "\n",
    "save_path = '/media/rene/Data/data/idc/sample/models'\n",
    "PATH = '/media/rene/Data/data/idc'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "dataloaders_valid, dataset_sizes_valid = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid', size=197)\n",
    "dataloaders_test, dataset_sizes_test = make_batch_gen(PATH, batch_size, num_workers, valid_name='test', size=197)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# get the proper model architecture\n",
    "model_ft = model_arch(pretrained=False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.cuda()\n",
    "\n",
    "# load the saved weights\n",
    "model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name)))\n",
    "print('Sample Model Validation: ')\n",
    "valid_loss, valid_acc = eval_model(model_ft, dataloaders_valid['valid'], dataset_sizes_valid['valid'], criterion)\n",
    "\n",
    "print('Sample Model Test: ', model_name)\n",
    "test_loss, test_acc = eval_model(model_ft, dataloaders_test['test'], dataset_sizes_test['test'], criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation:  resnet34_0\n",
      "Loss: 0.2428 Acc: 0.8993\n",
      "Test:  resnet34_0\n",
      "Loss: 0.2463 Acc: 0.8979\n",
      "Validation:  resnet34_1\n",
      "Loss: 0.2497 Acc: 0.8951\n",
      "Test:  resnet34_1\n",
      "Loss: 0.2530 Acc: 0.8943\n",
      "Validation:  resnet34_2\n",
      "Loss: 0.2461 Acc: 0.8969\n",
      "Test:  resnet34_2\n",
      "Loss: 0.2486 Acc: 0.8971\n",
      "Validation:  resnet34_3\n",
      "Loss: 0.2496 Acc: 0.8958\n",
      "Test:  resnet34_3\n",
      "Loss: 0.2524 Acc: 0.8945\n",
      "Validation:  resnet34_4\n",
      "Loss: 0.2463 Acc: 0.8962\n",
      "Test:  resnet34_4\n",
      "Loss: 0.2496 Acc: 0.8960\n",
      "Validation:  resnet34_5\n",
      "Loss: 0.2486 Acc: 0.8973\n",
      "Test:  resnet34_5\n",
      "Loss: 0.2505 Acc: 0.8966\n"
     ]
    }
   ],
   "source": [
    "model_list = [resnet34, resnet34, resnet34, resnet34, resnet34, resnet34]\n",
    "model_name = ['resnet34_0', 'resnet34_1', 'resnet34_2', 'resnet34_3', 'resnet34_4', 'resnet34_5']  \n",
    "\n",
    "save_path = '/media/rene/Data/data/idc/models'\n",
    "PATH = '/media/rene/Data/data/idc'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "dataloaders_valid, dataset_sizes_valid = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid', size=197)\n",
    "dataloaders_test, dataset_sizes_test = make_batch_gen(PATH, batch_size, num_workers, valid_name='test', size=197)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "results = {}\n",
    "\n",
    "for idx, model_arch in enumerate(model_list):\n",
    "    # get the proper model architecture\n",
    "    model_ft = model_arch(pretrained=False)\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "    model_ft = model_ft.cuda()\n",
    "    \n",
    "    # load the saved weights\n",
    "    model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name[idx])))\n",
    "    print('Validation: ', model_name[idx])\n",
    "    valid_loss, valid_acc = eval_model(model_ft, dataloaders_valid['valid'], dataset_sizes_valid['valid'], criterion)\n",
    "    \n",
    "    print('Test: ', model_name[idx])\n",
    "    test_loss, test_acc = eval_model(model_ft, dataloaders_test['test'], dataset_sizes_test['test'], criterion)\n",
    "    results[model_name[idx]] = [valid_acc, test_acc]\n",
    "    \n",
    "f = open(os.path.join(save_path, \"resnet34_all6.pkl\"),\"wb\")\n",
    "pickle.dump(results,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('resnet34_1', 0.8950731461240962), ('resnet34_3', 0.895841841024286), ('resnet34_4', 0.896178145043119), ('resnet34_2', 0.8969468399433087), ('resnet34_5', 0.8973311873934037), ('resnet34_0', 0.8993009680751399)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "results2 = {key:value[0] for (key,value) in results.items()}\n",
    "sorted_x = sorted(results2.items(), key=operator.itemgetter(1))\n",
    "print(sorted_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity/Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arch = resnet34\n",
    "model_name = 'resnet34_2'\n",
    "\n",
    "save_path = '/home/rene/data/idc/models'\n",
    "PATH = '/home/rene/data/idc'\n",
    "num_workers = 4\n",
    "batch_size=64\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid', test_name='test', size=197)\n",
    "\n",
    "# get the proper model architecture\n",
    "model_ft = model_arch(pretrained=False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.cuda()\n",
    "\n",
    "# load the saved weights\n",
    "model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sensitivity: 0.9213245732774274, specificity: 0.8318342151675485, Acc: 0.8969468399433087\n",
      "Test sensitivity: 0.922548242135871, specificity: 0.8292124945006599, Acc: 0.8970669485214634\n"
     ]
    }
   ],
   "source": [
    "model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name)))\n",
    "\n",
    "all_labels, all_preds = get_preds(model_ft, dataloaders['valid'], dataset_sizes['valid'])\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Validation sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')\n",
    "\n",
    "all_labels, all_preds = get_preds(model_ft, dataloaders['test'], dataset_sizes['test'])\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Test sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/media/rene/Data/data/idc'\n",
    "num_workers = 6\n",
    "batch_size=32\n",
    "epochs = 10\n",
    "save_path = '/media/rene/Data/data/idc/models'\n",
    "\n",
    "dataloaders, dataset_sizes = make_batch_gen(PATH, batch_size, num_workers, valid_name='valid', test_name='test', size=299)\n",
    "model_name = 'inception_v3'\n",
    "\n",
    "model_ft = inception_v3(pretrained=False)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "model_ft = model_ft.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.7370 Acc: 0.8444\n",
      "valid Loss: 0.3178 Acc: 0.8643\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.6558 Acc: 0.8603\n",
      "valid Loss: 0.3149 Acc: 0.8735\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.6186 Acc: 0.8676\n",
      "valid Loss: 0.2857 Acc: 0.8805\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.5653 Acc: 0.8794\n",
      "valid Loss: 0.2660 Acc: 0.8876\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "best_acc, model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                                 epochs, dataloaders, dataset_sizes)\n",
    "torch.save(model_ft.state_dict(), os.path.join(save_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2526 Acc: 0.8956\n",
      "Validation:  0.2526020526853055 0.8956016238679767\n",
      "Test:  inception_v3\n",
      "Loss: 0.2560 Acc: 0.8919\n",
      "Test:  0.255982373306663 0.8918782579451825\n"
     ]
    }
   ],
   "source": [
    "model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name)))\n",
    "valid_loss, valid_acc = eval_model(model_ft, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "print('Validation: ', valid_loss, valid_acc)\n",
    "\n",
    "print('Test: ', model_name)\n",
    "test_loss, test_acc = eval_model(model_ft, dataloaders['test'], dataset_sizes['test'], criterion)\n",
    "print('Test: ', test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity/Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sensitivity: 0.9138956606533398, specificity: 0.8437960235640648, Acc: 0.8956016238679767\n",
      "Test sensitivity: 0.9138381201044387, specificity: 0.8306488306488307, Acc: 0.8918782579451825\n"
     ]
    }
   ],
   "source": [
    "model_ft.load_state_dict(torch.load(os.path.join(save_path, model_name)))\n",
    "\n",
    "all_labels, all_preds = get_preds(model_ft, dataloaders['valid'], dataset_sizes['valid'], criterion)\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Validation sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')\n",
    "\n",
    "all_labels, all_preds = get_preds(model_ft, dataloaders['test'], dataset_sizes['test'], criterion)\n",
    "metrics = get_metrics_bin(all_labels, all_preds)\n",
    "print(f'Test sensitivity: {metrics[\"TPR\"]}, specificity: {metrics[\"TNR\"]}, Acc: {metrics[\"ACC\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
